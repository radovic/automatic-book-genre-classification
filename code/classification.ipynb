{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe2bd06",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1e1f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: joblib in /home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in /home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages (from nltk) (8.1.3)\n"
     ]
    }
   ],
   "source": [
    "# installation of packages\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68770765",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/filip/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/filip/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/filip/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# installation of NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbf03f",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f99e8fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>frbs_id</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>['humor', 'realistic fiction', \"children's lit...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>['humor', 'science fiction']</td>\n",
       "      <td>Alex, a teenager living in near-future England...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>['realistic fiction']</td>\n",
       "      <td>The text of The Plague is divided into five pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['science fiction', 'fantasy']</td>\n",
       "      <td>The novel posits that space around the Milky W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2152</td>\n",
       "      <td>/m/0x5g</td>\n",
       "      <td>All Quiet on the Western Front</td>\n",
       "      <td>Erich Maria Remarque</td>\n",
       "      <td>1929-01-29</td>\n",
       "      <td>['historical', 'realistic fiction']</td>\n",
       "      <td>The book tells the story of Paul Bäumer, a Ger...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  wiki_id  frbs_id                            name  \\\n",
       "0           0      620  /m/0hhy                     Animal Farm   \n",
       "1           1      843  /m/0k36              A Clockwork Orange   \n",
       "2           2      986  /m/0ldx                      The Plague   \n",
       "3           3     2080  /m/0wkt            A Fire Upon the Deep   \n",
       "4           4     2152  /m/0x5g  All Quiet on the Western Front   \n",
       "\n",
       "                 author        date  \\\n",
       "0         George Orwell  1945-08-17   \n",
       "1       Anthony Burgess        1962   \n",
       "2          Albert Camus        1947   \n",
       "3          Vernor Vinge         NaN   \n",
       "4  Erich Maria Remarque  1929-01-29   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['humor', 'realistic fiction', \"children's lit...   \n",
       "1                       ['humor', 'science fiction']   \n",
       "2                              ['realistic fiction']   \n",
       "3                     ['science fiction', 'fantasy']   \n",
       "4                ['historical', 'realistic fiction']   \n",
       "\n",
       "                                             summary  \n",
       "0  Old Major, the old boar on the Manor Farm, cal...  \n",
       "1  Alex, a teenager living in near-future England...  \n",
       "2  The text of The Plague is divided into five pa...  \n",
       "3  The novel posits that space around the Milky W...  \n",
       "4  The book tells the story of Paul Bäumer, a Ger...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# reading the dataset \n",
    "df = pd.read_csv('../data/dataset_filtered_labels.csv')\n",
    "\n",
    "# getting the list of genres \n",
    "genres = set()\n",
    "for v in df['genres'].values: genres = set(list(genres) + ast.literal_eval(v))\n",
    "genres = list(genres)\n",
    "\n",
    "# creating the mappings from genres to id and vice versa\n",
    "genre2id = {k:v for (v, k) in enumerate(genres)}\n",
    "id2genre = {k:v for (k, v) in enumerate(genres)}\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8bfcf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = df['summary'].to_numpy() # corpus - predictor variables\n",
    "Y = np.full((X.shape[0], len(genres)), 0, dtype=int) # genres - target variables\n",
    "\n",
    "# populating Y\n",
    "\n",
    "genre_data = df['genres'].to_numpy() # genres assigned to works\n",
    "for idx in range(len(Y)):\n",
    "    genre_data[idx] = ast.literal_eval(genre_data[idx])\n",
    "    for g in genre_data[idx]: Y[idx][genre2id[g]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74c18128",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "# Search of optimal value for min_df\n",
    "\n",
    "for val in [0, 0.000625, 0.00125, 0.001875, 0.0025, 0.005, 0.01]:\n",
    "    opt_X_train, opt_X_test, opt_Y_train, opt_Y_test = train_test_split(X, Y, random_state=2023)\n",
    "    vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(), min_df=val)\n",
    "    base_twcnb = ComplementNB()\n",
    "    clf_twcnb = OneVsRestClassifier(base_twcnb)\n",
    "    opt_X_train = vectorizer.fit_transform(opt_X_train)\n",
    "    opt_X_test = vectorizer.transform(opt_X_test)\n",
    "    clf_twcnb.fit(opt_X_train, opt_Y_train)\n",
    "    print(f'{val * 100: .2f}% -> {clf_twcnb.score(X_test, Y_test)}')\n",
    "\n",
    "# 0% -> 0.060659186535764374\n",
    "# 0.0625% -> 0.2699859747545582\n",
    "# 0.125% -> 0.3159186535764376 < OPTIMAL >\n",
    "# 0.1875% -> 0.3075035063113605\n",
    "# 0.25% -> 0.28856942496493687\n",
    "# 0.5% -> 0.22300140252454417\n",
    "# 1.0% -> 0.15252454417952313"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718bae91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# defining tokenizer which performs lemmatization and skips stop or/and non-alphabetic words\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.stops = set(stopwords.words('english'))\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t).lower() for t in word_tokenize(doc) if self.wnl.lemmatize(t) not in self.stops and t.isalpha()]\n",
    "    \n",
    "# defining TF-IDF vectorizer\n",
    "# we put threshold of 1% for term presence in summaries so we can filter out the least common terms\n",
    "# which can cause the overfitting of the classifier (this choice is backed by Zipf's law)\n",
    "vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(), min_df=0.00125)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe3450",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c9d3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_validate, KFold\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, hamming_loss\n",
    "\n",
    "from datetime import datetime\n",
    "from scipy.stats import randint\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db5cc909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report performance\n",
    "def report_performance_on_test_sets(scores):\n",
    "    import numpy as np\n",
    "    \n",
    "    print('F1 micro score: mean = %.3f, standard deviation = %.3f' %(np.mean(scores['test_F1 micro']), \n",
    "                                                                 np.std(scores['test_F1 micro'])))\n",
    "    \n",
    "    print('Accuracy: mean = %.3f, standard deviation = %.3f' %(np.mean(scores['test_Accuracy']), \n",
    "                                                                 np.std(scores['test_Accuracy'])))\n",
    "    \n",
    "    print('Hamming loss: mean = %.3f, standard deviation = %.3f' %(np.mean(scores['test_Hamming loss']), \n",
    "                                                                 np.std(scores['test_Hamming loss'])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f634a",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c70c32e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to perform multiple model evaluation:  0:06:55.276302\n",
      "F1 micro score: mean = 0.557, standard deviation = 0.007\n",
      "Accuracy: mean = 0.316, standard deviation = 0.007\n",
      "Hamming loss: mean = 0.078, standard deviation = 0.001\n"
     ]
    }
   ],
   "source": [
    "st=datetime.now() \n",
    "\n",
    "# defining the model and fitting\n",
    "base_twcnb = ComplementNB()\n",
    "clf_twcnb = OneVsRestClassifier(base_twcnb)\n",
    "\n",
    "steps = list()\n",
    "steps.append(('tfidf', TfidfVectorizer(tokenizer=LemmaTokenizer(), min_df=0.00125)))\n",
    "steps.append(('model', clf_twcnb))\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "\n",
    "scoring = {\"F1 micro\": \"f1_micro\", \"Accuracy\": make_scorer(accuracy_score), \n",
    "           \"Hamming loss\": make_scorer(hamming_loss)}\n",
    "\n",
    "mnb_scores = cross_validate(pipeline, X=X, y=Y, cv=cv, scoring = scoring, return_estimator = True)\n",
    "\n",
    "print(\"Time taken to perform multiple model evaluation: \",datetime.now()-st)\n",
    "report_performance_on_test_sets(mnb_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6505cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/filip/Desktop/Courses/data-literacy/project/code\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!CHANGE ACCORDINGLY!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e203b5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/scores/allgenres/MNB_scores.pkl', 'wb') as f:\n",
    "    pickle.dump(mnb_scores, f)\n",
    "        \n",
    "#with open('./data/scores/allgenres/MNB_scores.pkl', 'rb') as f:\n",
    "#    MNB_scores = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3058abf",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e8514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_and_evaluate_model(model, param_space, X, Y):\n",
    "    \n",
    "    # define the pipeline\n",
    "    steps = list()\n",
    "    steps.append(('tfidf', TfidfVectorizer(tokenizer=LemmaTokenizer(), min_df=0.00125)))\n",
    "    steps.append(('model', model))\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "\n",
    "    inner_cv = KFold(n_splits=2, shuffle=True, random_state=2023) # for hyperparameter tuning\n",
    "    outer_cv = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "\n",
    "    #defining scoring for k fold cross validation\n",
    "    scoring = {\"F1 micro\": \"f1_micro\", \"Accuracy\": make_scorer(accuracy_score), \n",
    "               \"Hamming loss\": make_scorer(hamming_loss)}\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    # for  hypoparameter tuning f1 score will be used to find the best parameters for refitting the \n",
    "    # estimator at the end. It is specified with the parameter refit = 'F1 micro'.\n",
    "    clf = RandomizedSearchCV(pipeline, param_space, n_iter=3, scoring = scoring, cv = inner_cv, \n",
    "                             refit = 'F1 micro')\n",
    "    \n",
    "    scores = cross_validate(clf, X=X, y=Y, cv=outer_cv, return_estimator = True, scoring = scoring)\n",
    "\n",
    "    # report performance\n",
    "    report_performance_on_test_sets(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e71523e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro score: mean = 0.563, standard deviation = 0.007\n",
      "Accuracy: mean = 0.331, standard deviation = 0.004\n",
      "Hamming loss: mean = 0.071, standard deviation = 0.001\n",
      "Time taken to perform hyperparameter tuning and multiple model evaluation:  0:46:21.942452\n"
     ]
    }
   ],
   "source": [
    "st=datetime.now() \n",
    "\n",
    "clf_lr = OneVsRestClassifier(LogisticRegression(max_iter = 200))\n",
    "param_space = {\n",
    "              'model__estimator__C':[0.01,0.1,1,5,10] \n",
    "              }\n",
    "lr_scores = tune_and_evaluate_model(clf_lr, param_space, X, Y)\n",
    "\n",
    "print(\"Time taken to perform hyperparameter tuning and multiple model evaluation: \",datetime.now()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "891b0dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/scores/allgenres/LR_scores.pkl', 'wb') as g:\n",
    "    pickle.dump(lr_scores, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5a0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/scores/allgenres/LR_scores.pkl', 'rb') as g:\n",
    "#    lr_scores = pickle.load(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be051ba4",
   "metadata": {},
   "source": [
    "### Random forest classifier\n",
    "Inherently supports mulitilabel classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b6428d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 micro score: mean = 0.236, standard deviation = 0.027\n",
      "Accuracy: mean = 0.119, standard deviation = 0.011\n",
      "Hamming loss: mean = 0.104, standard deviation = 0.004\n",
      "Time taken to perform hyperparameter tuning and multiple model evaluation:  0:24:37.072580\n"
     ]
    }
   ],
   "source": [
    "st=datetime.now() \n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = 2)\n",
    "\n",
    "param_space = {\n",
    "              'model__max_depth':list(np.arange(10, 250, step=50))\n",
    "              }\n",
    "rf_scores = tune_and_evaluate_model(rf, param_space, X, Y)\n",
    "print(\"Time taken to perform hyperparameter tuning and multiple model evaluation: \",datetime.now()-st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f33b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/scores/allgenres/RF_scores.pkl', 'wb') as h:\n",
    "    pickle.dump(rf_scores, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2f04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/scores/allgenres/RF_scores.pkl', 'rb') as h:\n",
    "#    rf_scores = pickle.load(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ffc59a",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc6009d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 2 is smaller than n_iter=3. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 2 is smaller than n_iter=3. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 2 is smaller than n_iter=3. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 2 is smaller than n_iter=3. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "/home/filip/Programs/miniconda3/envs/data_literacy/lib/python3.10/site-packages/sklearn/model_selection/_search.py:306: UserWarning: The total space of parameters 2 is smaller than n_iter=3. Running 2 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# define the classifier\n",
    "st=datetime.now() \n",
    "\n",
    "xgboost = xgb.XGBClassifier(objective = 'multi:softmax',                                  \n",
    "                            seed = 2023,  \n",
    "                            num_class=2,\n",
    "                            gamma =  0.1,\n",
    "                            learning_rate = 0.5,\n",
    "                            n_estimators = 200\n",
    "                            \n",
    "                         ) \n",
    "one_vs_rest_xgboost = OneVsRestClassifier(xgboost)\n",
    "\n",
    "param_space = {\n",
    "              'model__estimator__max_depth':list(np.arange(3,5, step=1))\n",
    "              }\n",
    "xgboost_scores = tune_and_evaluate_model(one_vs_rest_xgboost, param_space, X, Y)\n",
    "print(\"Time taken to perform hyperparameter tuning and multiple model evaluation: \",datetime.now()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460ebf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/scores/allgenres/XGBoost_scores.pkl', 'wb') as i:\n",
    "    pickle.dump(xgboost_scores, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e906cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/scores/allgenres/XGBoost_scores.pkl', 'rb') as i:\n",
    "#    xgboost_scores = pickle.load(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee81695d",
   "metadata": {},
   "source": [
    "## Evaluation of the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9907164",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores_f1 =  {'Multinomial naive Bayes': mnb_scores['test_F1 micro'], \n",
    "                     'Logistic regression': lr_scores['test_F1 micro'],\n",
    "                     'Random forest': nrf_scores['test_F1 micro'],\n",
    "                     'XGBoost' : xgboost_scores['test_F1 micro']\n",
    "                    }\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(models_scores_f1.values(), showmeans=True, meanline = True)\n",
    "ax.set_xticklabels(models_scores_f1.keys())\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"F1 (micro) score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffc0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores_accuracy = {'Multinomial naive Bayes': mnb_scores['test_Accuracy'], \n",
    "                 'Logistic regression': lr_scores['test_Accuracy'],\n",
    "                 'Random forest': nrf_scores['test_Accuracy'],\n",
    "                 'XGBoost' : xgboost_scores['test_Accuracy']\n",
    "                }\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(models_scores_accuracy.values(), showmeans=True, meanline = True)\n",
    "ax.set_xticklabels(models_scores_accuracy.keys())\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores_hamming = {'Multinomial naive Bayes': mnb_scores['test_Hamming loss'], \n",
    "                         'Logistic regression': lr_scores['test_Hamming loss'],\n",
    "                         'Random forest': nrf_scores['test_Hamming loss'],\n",
    "                         'XGBoost' : xgboost_scores['test_Hamming loss']\n",
    "                        }\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(models_scores_hamming.values(), showmeans=True, meanline = True)\n",
    "ax.set_xticklabels(models_scores_hamming.keys())\n",
    "ax.set_xlabel(\"Model\")\n",
    "ax.set_ylabel(\"Hamming loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
