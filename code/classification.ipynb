{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe2bd06",
   "metadata": {},
   "source": [
    "# Classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e1f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation of packages\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68770765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installation of NLTK data\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fbf03f",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f99e8fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>wiki_id</th>\n",
       "      <th>frbs_id</th>\n",
       "      <th>name</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>genres</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>620</td>\n",
       "      <td>/m/0hhy</td>\n",
       "      <td>Animal Farm</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>1945-08-17</td>\n",
       "      <td>['humor', 'realistic fiction', \"children's lit...</td>\n",
       "      <td>Old Major, the old boar on the Manor Farm, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>843</td>\n",
       "      <td>/m/0k36</td>\n",
       "      <td>A Clockwork Orange</td>\n",
       "      <td>Anthony Burgess</td>\n",
       "      <td>1962</td>\n",
       "      <td>['humor', 'science fiction']</td>\n",
       "      <td>Alex, a teenager living in near-future England...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>986</td>\n",
       "      <td>/m/0ldx</td>\n",
       "      <td>The Plague</td>\n",
       "      <td>Albert Camus</td>\n",
       "      <td>1947</td>\n",
       "      <td>['realistic fiction']</td>\n",
       "      <td>The text of The Plague is divided into five pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2080</td>\n",
       "      <td>/m/0wkt</td>\n",
       "      <td>A Fire Upon the Deep</td>\n",
       "      <td>Vernor Vinge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['science fiction', 'fantasy']</td>\n",
       "      <td>The novel posits that space around the Milky W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2152</td>\n",
       "      <td>/m/0x5g</td>\n",
       "      <td>All Quiet on the Western Front</td>\n",
       "      <td>Erich Maria Remarque</td>\n",
       "      <td>1929-01-29</td>\n",
       "      <td>['historical', 'realistic fiction']</td>\n",
       "      <td>The book tells the story of Paul Bäumer, a Ger...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  wiki_id  frbs_id                            name  \\\n",
       "0           0      620  /m/0hhy                     Animal Farm   \n",
       "1           1      843  /m/0k36              A Clockwork Orange   \n",
       "2           2      986  /m/0ldx                      The Plague   \n",
       "3           3     2080  /m/0wkt            A Fire Upon the Deep   \n",
       "4           4     2152  /m/0x5g  All Quiet on the Western Front   \n",
       "\n",
       "                 author        date  \\\n",
       "0         George Orwell  1945-08-17   \n",
       "1       Anthony Burgess        1962   \n",
       "2          Albert Camus        1947   \n",
       "3          Vernor Vinge         NaN   \n",
       "4  Erich Maria Remarque  1929-01-29   \n",
       "\n",
       "                                              genres  \\\n",
       "0  ['humor', 'realistic fiction', \"children's lit...   \n",
       "1                       ['humor', 'science fiction']   \n",
       "2                              ['realistic fiction']   \n",
       "3                     ['science fiction', 'fantasy']   \n",
       "4                ['historical', 'realistic fiction']   \n",
       "\n",
       "                                             summary  \n",
       "0  Old Major, the old boar on the Manor Farm, cal...  \n",
       "1  Alex, a teenager living in near-future England...  \n",
       "2  The text of The Plague is divided into five pa...  \n",
       "3  The novel posits that space around the Milky W...  \n",
       "4  The book tells the story of Paul Bäumer, a Ger...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "# reading the dataset \n",
    "df = pd.read_csv('../data/dataset_filtered_labels.csv')\n",
    "\n",
    "# getting the list of genres \n",
    "genres = set()\n",
    "for v in df['genres'].values: genres = set(list(genres) + ast.literal_eval(v))\n",
    "genres = list(genres)\n",
    "\n",
    "# creating the mappings from genres to id and vice versa\n",
    "genre2id = {k:v for (v, k) in enumerate(genres)}\n",
    "id2genre = {k:v for (k, v) in enumerate(genres)}\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34795859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "X = df['summary'].to_numpy() # corpus - predictor variables\n",
    "Y = np.full((X.shape[0], len(genres)), 1, dtype=int) # genres - target variables\n",
    "\n",
    "# populating Y\n",
    "genre_data = df['genres'].to_numpy() # genres assigned to works\n",
    "for idx in range(len(Y)):\n",
    "    genre_data[idx] = ast.literal_eval(genre_data[idx])\n",
    "    for g in genre_data[idx]: Y[idx][genre2id[g]] = 0\n",
    "\n",
    "# splitting dataset in train and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718bae91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# defining tokenizer which performs lemmatization and skips stop or/and non-alphabetic words\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.stops = set(stopwords.words('english'))\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc) if self.wnl.lemmatize(t) not in self.stops and t.isalpha()]\n",
    "    \n",
    "# defining TF-IDF vectorizer\n",
    "# we put threshold of 1% for term presence in summaries so we can filter out the least common terms\n",
    "# which can cause the overfitting of the classifier (this choice is backed by Zipf's law)\n",
    "vectorizer = TfidfVectorizer(tokenizer=LemmaTokenizer(), min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42b94f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8554, 2885) (2852, 2885)\n"
     ]
    }
   ],
   "source": [
    "X_train = vectorizer.fit_transform(X_train) # learning normalized TF-IDF weights\n",
    "X_test = vectorizer.transform(X_test) # calculating TF-IDF weights\n",
    "\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe3450",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f634a",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c70c32e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15252454417952313"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# defining the model and fitting\n",
    "base_twcnb = ComplementNB()\n",
    "clf = OneVsRestClassifier(base_twcnb)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "clf.score(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
